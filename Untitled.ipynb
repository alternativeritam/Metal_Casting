{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c376f11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70c40037",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "for dirname, _, filenames in os.walk('train'):\n",
    "    for filename in filenames:\n",
    "        pass\n",
    "        #print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "711170c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "241b37ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = 'train/casting_data'\n",
    "TRAIN_DIR = 'train/casting_data/train'\n",
    "TEST_DIR = 'train/casting_data/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65add014",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'head' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "ls '{TRAIN_DIR}'|head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa00ae75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import transforms\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2448d84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ImageFolder(TRAIN_DIR, transform = transforms.ToTensor())\n",
    "test_dataset = ImageFolder(TEST_DIR, transform = transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14835fac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2da2d68aa70>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "efb043be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6133, 500)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ds = test_dataset\n",
    "val_size =  500\n",
    "train_size = len(dataset)-val_size\n",
    "train_ds,val_ds = random_split(dataset,[train_size,val_size])\n",
    "len(train_ds),len(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "032accfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "14dbb1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n",
    "\n",
    "class ImageClassificationBase(nn.Module):\n",
    "    def training_step(self, batch):\n",
    "        images, labels = batch \n",
    "        out = self(images)                 \n",
    "        loss = F.cross_entropy(out, labels) \n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        images, labels = batch \n",
    "        out = self(images)                   \n",
    "        loss = F.cross_entropy(out, labels)   \n",
    "        acc = accuracy(out, labels)          \n",
    "        return {'val_loss': loss.detach(), 'val_acc': acc}\n",
    "        \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()   \n",
    "        batch_accs = [x['val_acc'] for x in outputs]\n",
    "        epoch_acc = torch.stack(batch_accs).mean()     \n",
    "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
    "    \n",
    "    def epoch_end(self, epoch, result):\n",
    "        print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n",
    "            epoch, result['train_loss'], result['val_loss'], result['val_acc']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e566e756",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetalCastingCnnModel(ImageClassificationBase):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2), # output: 64 x 16 x 16\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2), # output: 128 x 8 x 8\n",
    "\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2), # output: 256 x 4 x 4\n",
    "\n",
    "            nn.Flatten(), \n",
    "            nn.Linear(21904*4*4, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 2))\n",
    "        \n",
    "    def forward(self, xb):\n",
    "        return self.network(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7897fc0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MetalCastingCnnModel(\n",
       "  (network): Sequential(\n",
       "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU()\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU()\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU()\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU()\n",
       "    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (15): Flatten(start_dim=1, end_dim=-1)\n",
       "    (16): Linear(in_features=350464, out_features=1024, bias=True)\n",
       "    (17): ReLU()\n",
       "    (18): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    (19): ReLU()\n",
       "    (20): Linear(in_features=512, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MetalCastingCnnModel()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7d6652c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "81f65904",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MetalCastingCnnModel(\n",
       "  (network): Sequential(\n",
       "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU()\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU()\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU()\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU()\n",
       "    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (15): Flatten(start_dim=1, end_dim=-1)\n",
       "    (16): Linear(in_features=350464, out_features=1024, bias=True)\n",
       "    (17): ReLU()\n",
       "    (18): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    (19): ReLU()\n",
       "    (20): Linear(in_features=512, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"Metal_Casting.pth\"\n",
    "model.load_state_dict(torch.load(path,map_location ='cpu'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5fdffb6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_device(data, device):\n",
    "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
    "    if isinstance(data, (list,tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2447bf11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_single(image):\n",
    "    xb = image.unsqueeze(0)\n",
    "    xb = to_device(xb, device)\n",
    "    preds = model(xb)\n",
    "    prediction = preds[0]\n",
    "    print(\"Prediction: \", prediction)\n",
    "    #plt.imshow(image.permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3161f439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:  tensor([ 18.0183, -19.8146], grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "predict_single(test_ds[100][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "843d7b38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test_ds[100][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d5db3c74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.5608, 0.5608, 0.5569,  ..., 0.6627, 0.6627, 0.6588],\n",
       "         [0.5569, 0.5529, 0.5529,  ..., 0.6627, 0.6588, 0.6588],\n",
       "         [0.5451, 0.5451, 0.5490,  ..., 0.6588, 0.6588, 0.6588],\n",
       "         ...,\n",
       "         [0.6588, 0.6588, 0.6588,  ..., 0.7255, 0.7255, 0.7255],\n",
       "         [0.6588, 0.6588, 0.6588,  ..., 0.7255, 0.7255, 0.7255],\n",
       "         [0.6588, 0.6588, 0.6588,  ..., 0.7255, 0.7255, 0.7255]],\n",
       "\n",
       "        [[0.5608, 0.5608, 0.5569,  ..., 0.6627, 0.6627, 0.6588],\n",
       "         [0.5569, 0.5529, 0.5529,  ..., 0.6627, 0.6588, 0.6588],\n",
       "         [0.5451, 0.5451, 0.5490,  ..., 0.6588, 0.6588, 0.6588],\n",
       "         ...,\n",
       "         [0.6588, 0.6588, 0.6588,  ..., 0.7255, 0.7255, 0.7255],\n",
       "         [0.6588, 0.6588, 0.6588,  ..., 0.7255, 0.7255, 0.7255],\n",
       "         [0.6588, 0.6588, 0.6588,  ..., 0.7255, 0.7255, 0.7255]],\n",
       "\n",
       "        [[0.5608, 0.5608, 0.5569,  ..., 0.6627, 0.6627, 0.6588],\n",
       "         [0.5569, 0.5529, 0.5529,  ..., 0.6627, 0.6588, 0.6588],\n",
       "         [0.5451, 0.5451, 0.5490,  ..., 0.6588, 0.6588, 0.6588],\n",
       "         ...,\n",
       "         [0.6588, 0.6588, 0.6588,  ..., 0.7255, 0.7255, 0.7255],\n",
       "         [0.6588, 0.6588, 0.6588,  ..., 0.7255, 0.7255, 0.7255],\n",
       "         [0.6588, 0.6588, 0.6588,  ..., 0.7255, 0.7255, 0.7255]]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ds[100][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3146cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
